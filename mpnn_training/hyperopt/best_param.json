{"activation": "ReLU",
  "aggregation": "mean",
  "batch-size": 70,
  "message-bias": "",
  "depth": 4,
  "dropout": 0.07928777915219476,
  "ffn-hidden-dim": 100,
  "ffn-num-layers": 2,
  "final-lr": 0.0008745233959951397,
  "message-hidden-dim ": 300,
  "init-lr": 0.0010170618974826723,
  "max-lr": 0.008213119797581435,
  "warmup-epochs": 5,
  "id": "f8f937d8-e7f3-4073-a91c-e50fa78313d7"}